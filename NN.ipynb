{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fsveFS7ikyu"
      },
      "source": [
        "# Klassifikation mit einem Neuronalen Netz\n",
        "\n",
        "## Trainingsdaten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "bWQuIIshiky6"
      },
      "outputs": [],
      "source": [
        "# %pip install torch\n",
        "# %pip install torchvision\n",
        "# %pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "jux-RX43iky6"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def load(data):\n",
        "    return np.load(data)['arr_0']\n",
        "# load dataset\n",
        "train_data = load('Data\\K49-data\\k49-train-imgs.npz')\n",
        "test_data = load('Data\\K49-data\\k49-test-imgs.npz')\n",
        "\n",
        "train_labels = load('Data\\K49-data\\k49-train-labels.npz')\n",
        "test_labels = load('Data\\K49-data\\k49-test-labels.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rpfYCWmiky7",
        "outputId": "618206a4-4ae5-46c3-d236-f680c5b7c633"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((232365, 28, 28), (38547, 28, 28))"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.data.shape, test_data.data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkdXQsEAiky8"
      },
      "source": [
        "## Definition des Neuronalen Netzes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "YNrh6L-Piky8"
      },
      "outputs": [],
      "source": [
        "# set parameters for feed forward neural network\n",
        "input_size = 28*28 #=784\n",
        "hidden_size = 5000\n",
        "num_classes = 49\n",
        "num_epochs = 15\n",
        "batch_size = 2048\n",
        "learning_rate = 0.001\n",
        "\n",
        "#combine labels and data\n",
        "train_data = train_data.astype(np.float32)  # Or any other appropriate data type\n",
        "\n",
        "dataset = TensorDataset(torch.tensor(train_data), torch.tensor(train_labels))\n",
        "\n",
        "# create dataloader\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# create neural network\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, hidden_size).to(dtype=torch.float32) # Hidden layer\n",
        "        self.relu = nn.ReLU() # Activation function\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes).to(dtype=torch.float32) # Output layer\n",
        "\n",
        "    def forward(self, x):  # Forward pass\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgj0UDJziky9"
      },
      "source": [
        "Wie erwartet sind die Gewichte des Neuronalen Netzes vor dem Training zufällig gewählt, so dass die Klassifikation misslingt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITU5062Viky9"
      },
      "source": [
        "## Training des Neuronalen Netz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEKoVx03iky-",
        "outputId": "2964e996-7956-4207-f528-fc87a58baf41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/15], Step [100/114], Loss: 0.8524\n",
            "Epoch [2/15], Step [100/114], Loss: 0.5575\n",
            "Epoch [3/15], Step [100/114], Loss: 0.4576\n",
            "Epoch [4/15], Step [100/114], Loss: 0.3852\n",
            "Epoch [5/15], Step [100/114], Loss: 0.3156\n",
            "Epoch [6/15], Step [100/114], Loss: 0.2458\n",
            "Epoch [7/15], Step [100/114], Loss: 0.2242\n",
            "Epoch [8/15], Step [100/114], Loss: 0.1772\n",
            "Epoch [9/15], Step [100/114], Loss: 0.1747\n",
            "Epoch [10/15], Step [100/114], Loss: 0.1615\n",
            "Epoch [11/15], Step [100/114], Loss: 0.1368\n",
            "Epoch [12/15], Step [100/114], Loss: 0.1558\n",
            "Epoch [13/15], Step [100/114], Loss: 0.1356\n",
            "Epoch [14/15], Step [100/114], Loss: 0.1350\n",
            "Epoch [15/15], Step [100/114], Loss: 0.1979\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (train_data, train_labels) in enumerate(train_loader):\n",
        "        # reshape images to (batch_size, input_size)\n",
        "        train_data = train_data.reshape(-1, 28*28)\n",
        "\n",
        "        # forward pass\n",
        "        outputs = model(train_data)\n",
        "        loss = criterion(outputs, train_labels)\n",
        "\n",
        "        # backward and optimize\n",
        "        optimizer.zero_grad() # clear gradients\n",
        "        loss.backward() # backpropagation\n",
        "        optimizer.step() # update weights\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                  .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04AChXxZiky-"
      },
      "source": [
        "## Test des Neuronalen Netzes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T4jfUH-iky-",
        "outputId": "1bae4f1a-e454-4d04-a663-e0fea0b6019f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on test images: 96.77834441503668 %\n"
          ]
        }
      ],
      "source": [
        "# test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on test images: {} %'.format(100 * correct / total))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "800min\n",
        "hidden_size = 240100\n",
        "\n",
        "num_classes = 49\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "batch_size = 500\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "Accuracy = 1.5587545456501624 %"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "47 min\n",
        "\n",
        "hidden_size = 24010\n",
        "\n",
        "num_classes = 49\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "batch_size = 500\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "Accuracy = 91.28913562713834 %"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUoIJhlriky_"
      },
      "source": [
        "## Test mit kleinerem Trainingsdatensatz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "lKe9Qreziky_"
      },
      "outputs": [],
      "source": [
        "# choose a small traings set randomly\n",
        "total_images = len(train_data)\n",
        "train_size =  int(0.25 * total_images)  # 70% der Bilder für das Training\n",
        "\n",
        "train_data = load('Data\\K49-data\\k49-train-imgs.npz')\n",
        "test_data = load('Data\\K49-data\\k49-test-imgs.npz')\n",
        "\n",
        "train_labels = load('Data\\K49-data\\k49-train-labels.npz')\n",
        "test_labels = load('Data\\K49-data\\k49-test-labels.npz')\n",
        "\n",
        "train_data = train_data.astype(np.float32)  # Or any other appropriate data type\n",
        "train_data_small = TensorDataset(torch.tensor(train_data[:train_size]), torch.tensor(train_labels[:train_size]))\n",
        "test_data_small = TensorDataset(torch.tensor(test_data[train_size:]), torch.tensor(test_labels[train_size:]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BVSa6nNikzA",
        "outputId": "377b51da-317b-4972-c152-9b1a2cbc28c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  4., ..., 23.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  4.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]], dtype=float32),\n",
              " <torch.utils.data.dataset.TensorDataset at 0x29ea929a0b0>)"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data, train_data_small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yERw8z5iikzA",
        "outputId": "25fd9345-01c2-47b9-c788-fc3bd1e25897"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [5/24], Loss: 188.2991\n",
            "Train Accuracy of the model on the train images: 21.27659574468085 %\n",
            "Correct: 50\n",
            "Total: 235\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 must have the same dtype",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\schmi\\Documents\\GitHub\\nn-character-recognition-of-natural-written-japanese\\NN.ipynb Cell 19\u001b[0m in \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/schmi/Documents/GitHub/nn-character-recognition-of-natural-written-japanese/NN.ipynb#X24sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mfor\u001b[39;00m images, labels \u001b[39min\u001b[39;00m test_loader_small:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/schmi/Documents/GitHub/nn-character-recognition-of-natural-written-japanese/NN.ipynb#X24sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m28\u001b[39m\u001b[39m*\u001b[39m\u001b[39m28\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/schmi/Documents/GitHub/nn-character-recognition-of-natural-written-japanese/NN.ipynb#X24sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model_small(images)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/schmi/Documents/GitHub/nn-character-recognition-of-natural-written-japanese/NN.ipynb#X24sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     _, predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs\u001b[39m.\u001b[39mdata, \u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/schmi/Documents/GitHub/nn-character-recognition-of-natural-written-japanese/NN.ipynb#X24sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\schmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[1;32mc:\\Users\\schmi\\Documents\\GitHub\\nn-character-recognition-of-natural-written-japanese\\NN.ipynb Cell 19\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/schmi/Documents/GitHub/nn-character-recognition-of-natural-written-japanese/NN.ipynb#X24sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):  \u001b[39m# Forward pass\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/schmi/Documents/GitHub/nn-character-recognition-of-natural-written-japanese/NN.ipynb#X24sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/schmi/Documents/GitHub/nn-character-recognition-of-natural-written-japanese/NN.ipynb#X24sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/schmi/Documents/GitHub/nn-character-recognition-of-natural-written-japanese/NN.ipynb#X24sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml2(out)\n",
            "File \u001b[1;32mc:\\Users\\schmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\schmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype"
          ]
        }
      ],
      "source": [
        "# train model_small on train_data_small\n",
        "# print loss and accuracy on train_data_small and test_data_small\n",
        "\n",
        "batch_size = 10\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "report = 5\n",
        "\n",
        "model_small = NeuralNet(input_size, hidden_size, num_classes)\n",
        "\n",
        "\n",
        "\n",
        "# create dataloader\n",
        "train_loader_small = DataLoader(dataset=train_data_small, batch_size=batch_size, shuffle=True)\n",
        "test_loader_small = DataLoader(dataset=test_data_small, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "# loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_small.parameters(), lr=learning_rate)\n",
        "\n",
        "# train the model\n",
        "total_step = len(train_loader_small)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader_small):\n",
        "        # reshape images to (batch_size, input_size)\n",
        "        images = images.reshape(-1, 28*28)\n",
        "\n",
        "        # forward pass\n",
        "        outputs = model_small(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print loss on train_data_small and test_data_small\n",
        "        if (i+1) % report == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                  .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "        # Print accuracy after processing all batches\n",
        "        if (i+1) % report == 0:\n",
        "        # Calculate accuracy on train_data_small\n",
        "            with torch.no_grad():\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                for images, labels in train_loader_small:\n",
        "                    images = images.reshape(-1, 28*28)\n",
        "                    outputs = model_small(images)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "                print('Train Accuracy of the model on the train images: {} %'.format(100 * correct / total))\n",
        "                print('Correct:', correct)\n",
        "                print('Total:', total)\n",
        "\n",
        "    # Calculate accuracy on test_data_small\n",
        "            with torch.no_grad():\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                for images, labels in test_loader_small:\n",
        "                    images = images.reshape(-1, 28*28)\n",
        "                    outputs = model_small(images)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "                print('Test Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
        "                print('Correct:', correct)\n",
        "                print('Total:', total)\n",
        "\n",
        "# ... (rest of your code)\n",
        "\n",
        "\n",
        "\n",
        "# test the model\n",
        "# In the test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM6ebafyikzB",
        "outputId": "6570e08d-7a99-4136-915c-2a7c05fab5e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 78.40896864846255 %\n"
          ]
        }
      ],
      "source": [
        "# test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
