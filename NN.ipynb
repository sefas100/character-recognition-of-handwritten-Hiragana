{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fsveFS7ikyu"
      },
      "source": [
        "# Klassifikation mit einem Neuronalen Netz\n",
        "\n",
        "## Trainingsdaten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bWQuIIshiky6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.1)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: filelock in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torchvision in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.15.2)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: numpy in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (1.25.1)\n",
            "Requirement already satisfied: requests in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (2.28.2)\n",
            "Requirement already satisfied: torch==2.0.1 in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (2.0.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (9.2.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.0.1->torchvision) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.0.1->torchvision) (4.7.1)\n",
            "Requirement already satisfied: sympy in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.0.1->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.0.1->torchvision) (3.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch==2.0.1->torchvision) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.7.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\sebastian\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (9.2.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\sebastian\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sebastian\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\sebastian\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# %pip install torch\n",
        "# %pip install torchvision\n",
        "# %pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jux-RX43iky6"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def load(data):\n",
        "    return np.load(data)['arr_0']\n",
        "# load dataset\n",
        "train_data = load('Data\\K49-data\\k49-train-imgs.npz')\n",
        "test_data = load('Data\\K49-data\\k49-test-imgs.npz')\n",
        "\n",
        "train_labels = load('Data\\K49-data\\k49-train-labels.npz')\n",
        "test_labels = load('Data\\K49-data\\k49-test-labels.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rpfYCWmiky7",
        "outputId": "618206a4-4ae5-46c3-d236-f680c5b7c633"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((232365, 28, 28), (38547, 28, 28))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.data.shape, test_data.data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkdXQsEAiky8"
      },
      "source": [
        "## Definition des Neuronalen Netzes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YNrh6L-Piky8"
      },
      "outputs": [],
      "source": [
        "# set parameters for feed forward neural network\n",
        "input_size = 28*28 #=784\n",
        "hidden_size = 24010\n",
        "num_classes = 49\n",
        "num_epochs = 10\n",
        "batch_size = 500\n",
        "learning_rate = 0.001\n",
        "\n",
        "#combine labels and data\n",
        "train_data = train_data.astype(np.float32)  # Or any other appropriate data type\n",
        "\n",
        "dataset = TensorDataset(torch.tensor(train_data), torch.tensor(train_labels))\n",
        "\n",
        "# create dataloader\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# create neural network\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, hidden_size).to(dtype=torch.float32) # Hidden layer\n",
        "        self.relu = nn.ReLU() # Activation function\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes).to(dtype=torch.float32) # Output layer\n",
        "\n",
        "    def forward(self, x):  # Forward pass\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgj0UDJziky9"
      },
      "source": [
        "Wie erwartet sind die Gewichte des Neuronalen Netzes vor dem Training zufällig gewählt, so dass die Klassifikation misslingt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITU5062Viky9"
      },
      "source": [
        "## Training des Neuronalen Netz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEKoVx03iky-",
        "outputId": "2964e996-7956-4207-f528-fc87a58baf41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [100/465], Loss: 0.8946\n",
            "Epoch [1/10], Step [200/465], Loss: 0.7867\n",
            "Epoch [1/10], Step [300/465], Loss: 0.7676\n",
            "Epoch [1/10], Step [400/465], Loss: 0.6484\n",
            "Epoch [2/10], Step [100/465], Loss: 0.5555\n",
            "Epoch [2/10], Step [200/465], Loss: 0.4887\n",
            "Epoch [2/10], Step [300/465], Loss: 0.4708\n",
            "Epoch [2/10], Step [400/465], Loss: 0.6739\n",
            "Epoch [3/10], Step [100/465], Loss: 0.5266\n",
            "Epoch [3/10], Step [200/465], Loss: 0.4359\n",
            "Epoch [3/10], Step [300/465], Loss: 0.5363\n",
            "Epoch [3/10], Step [400/465], Loss: 0.4644\n",
            "Epoch [4/10], Step [100/465], Loss: 0.3917\n",
            "Epoch [4/10], Step [200/465], Loss: 0.5257\n",
            "Epoch [4/10], Step [300/465], Loss: 0.5952\n",
            "Epoch [4/10], Step [400/465], Loss: 0.4679\n",
            "Epoch [5/10], Step [100/465], Loss: 0.5613\n",
            "Epoch [5/10], Step [200/465], Loss: 0.4719\n",
            "Epoch [5/10], Step [300/465], Loss: 0.5277\n",
            "Epoch [5/10], Step [400/465], Loss: 0.7372\n",
            "Epoch [6/10], Step [100/465], Loss: 0.4825\n",
            "Epoch [6/10], Step [200/465], Loss: 0.3636\n",
            "Epoch [6/10], Step [300/465], Loss: 0.5090\n",
            "Epoch [6/10], Step [400/465], Loss: 0.5593\n",
            "Epoch [7/10], Step [100/465], Loss: 0.4100\n",
            "Epoch [7/10], Step [200/465], Loss: 0.4602\n",
            "Epoch [7/10], Step [300/465], Loss: 0.4847\n",
            "Epoch [7/10], Step [400/465], Loss: 0.4701\n",
            "Epoch [8/10], Step [100/465], Loss: 0.4935\n",
            "Epoch [8/10], Step [200/465], Loss: 0.4914\n",
            "Epoch [8/10], Step [300/465], Loss: 0.4541\n",
            "Epoch [8/10], Step [400/465], Loss: 0.7300\n",
            "Epoch [9/10], Step [100/465], Loss: 0.3584\n",
            "Epoch [9/10], Step [200/465], Loss: 0.4407\n",
            "Epoch [9/10], Step [300/465], Loss: 0.6936\n",
            "Epoch [9/10], Step [400/465], Loss: 0.5145\n",
            "Epoch [10/10], Step [100/465], Loss: 0.5424\n",
            "Epoch [10/10], Step [200/465], Loss: 0.3762\n",
            "Epoch [10/10], Step [300/465], Loss: 0.5208\n",
            "Epoch [10/10], Step [400/465], Loss: 0.6412\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (train_data, train_labels) in enumerate(train_loader):\n",
        "        # reshape images to (batch_size, input_size)\n",
        "        train_data = train_data.reshape(-1, 28*28)\n",
        "\n",
        "        # forward pass\n",
        "        outputs = model(train_data)\n",
        "        loss = criterion(outputs, train_labels)\n",
        "\n",
        "        # backward and optimize\n",
        "        optimizer.zero_grad() # clear gradients\n",
        "        loss.backward() # backpropagation\n",
        "        optimizer.step() # update weights\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                  .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04AChXxZiky-"
      },
      "source": [
        "## Test des Neuronalen Netzes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T4jfUH-iky-",
        "outputId": "1bae4f1a-e454-4d04-a663-e0fea0b6019f"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m images, labels \u001b[39min\u001b[39;00m test_loader:\n\u001b[0;32m      7\u001b[0m     images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m28\u001b[39m\u001b[39m*\u001b[39m\u001b[39m28\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m     outputs \u001b[39m=\u001b[39m model(images)\n\u001b[0;32m      9\u001b[0m     _, predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs\u001b[39m.\u001b[39mdata, \u001b[39m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m     total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\Sebastian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "Cell \u001b[1;32mIn[3], line 28\u001b[0m, in \u001b[0;36mNeuralNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):  \u001b[39m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1(x)\n\u001b[0;32m     29\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n\u001b[0;32m     30\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml2(out)\n",
            "File \u001b[1;32mc:\\Users\\Sebastian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\Sebastian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on test images: {} %'.format(100 * correct / total))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "800min\n",
        "hidden_size = 240100\n",
        "\n",
        "num_classes = 49\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "batch_size = 500\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "Accuracy = 1.5587545456501624 %"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "47 min\n",
        "\n",
        "hidden_size = 24010\n",
        "\n",
        "num_classes = 49\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "batch_size = 500\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "Accuracy = 91.28913562713834 %"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUoIJhlriky_"
      },
      "source": [
        "## Test mit kleinerem Trainingsdatensatz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lKe9Qreziky_"
      },
      "outputs": [],
      "source": [
        "# choose a small traings set randomly\n",
        "total_images = len(train_data)\n",
        "train_size =  int(0.25 * total_images)  # 70% der Bilder für das Training\n",
        "\n",
        "train_data = load('Data\\K49-data\\k49-train-imgs.npz')\n",
        "test_data = load('Data\\K49-data\\k49-test-imgs.npz')\n",
        "\n",
        "train_labels = load('Data\\K49-data\\k49-train-labels.npz')\n",
        "test_labels = load('Data\\K49-data\\k49-test-labels.npz')\n",
        "\n",
        "train_data = train_data.astype(np.float32)  # Or any other appropriate data type\n",
        "train_data_small = TensorDataset(torch.tensor(train_data[:train_size]), torch.tensor(train_labels[:train_size]))\n",
        "test_data_small = TensorDataset(torch.tensor(test_data[train_size:]), torch.tensor(test_labels[train_size:]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BVSa6nNikzA",
        "outputId": "377b51da-317b-4972-c152-9b1a2cbc28c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  4., ..., 23.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  4.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]], dtype=float32),\n",
              " <torch.utils.data.dataset.TensorDataset at 0x200935b9410>)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data, train_data_small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yERw8z5iikzA",
        "outputId": "25fd9345-01c2-47b9-c788-fc3bd1e25897"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [5/5810], Loss: 679.5137\n",
            "Train Accuracy of the model on the train images: 8.696700005164312 %\n",
            "Correct: 5052\n",
            "Total: 58091\n"
          ]
        },
        {
          "ename": "ZeroDivisionError",
          "evalue": "division by zero",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 71\u001b[0m\n\u001b[0;32m     68\u001b[0m     total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m     69\u001b[0m     correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (predicted \u001b[39m==\u001b[39m labels)\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m---> 71\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTest Accuracy of the model on the test images: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m100\u001b[39;49m \u001b[39m*\u001b[39;49m correct \u001b[39m/\u001b[39;49m total))\n\u001b[0;32m     72\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mCorrect:\u001b[39m\u001b[39m'\u001b[39m, correct)\n\u001b[0;32m     73\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTotal:\u001b[39m\u001b[39m'\u001b[39m, total)\n",
            "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ],
      "source": [
        "# train model_small on train_data_small\n",
        "# print loss and accuracy on train_data_small and test_data_small\n",
        "\n",
        "batch_size = 10\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "report = 5\n",
        "\n",
        "model_small = NeuralNet(input_size, hidden_size, num_classes)\n",
        "\n",
        "\n",
        "\n",
        "# create dataloader\n",
        "train_loader_small = DataLoader(dataset=train_data_small, batch_size=batch_size, shuffle=True)\n",
        "test_loader_small = DataLoader(dataset=test_data_small, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "# loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_small.parameters(), lr=learning_rate)\n",
        "\n",
        "# train the model\n",
        "total_step = len(train_loader_small)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader_small):\n",
        "        # reshape images to (batch_size, input_size)\n",
        "        images = images.reshape(-1, 28*28)\n",
        "\n",
        "        # forward pass\n",
        "        outputs = model_small(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print loss on train_data_small and test_data_small\n",
        "        if (i+1) % report == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                  .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "        # Print accuracy after processing all batches\n",
        "        if (i+1) % report == 0:\n",
        "        # Calculate accuracy on train_data_small\n",
        "            with torch.no_grad():\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                for images, labels in train_loader_small:\n",
        "                    images = images.reshape(-1, 28*28)\n",
        "                    outputs = model_small(images)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "                print('Train Accuracy of the model on the train images: {} %'.format(100 * correct / total))\n",
        "                print('Correct:', correct)\n",
        "                print('Total:', total)\n",
        "\n",
        "    # Calculate accuracy on test_data_small\n",
        "            with torch.no_grad():\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                for images, labels in test_loader_small:\n",
        "                    images = images.reshape(-1, 28*28)\n",
        "                    outputs = model_small(images)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "                print('Test Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
        "                print('Correct:', correct)\n",
        "                print('Total:', total)\n",
        "\n",
        "# ... (rest of your code)\n",
        "\n",
        "\n",
        "\n",
        "# test the model\n",
        "# In the test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM6ebafyikzB",
        "outputId": "6570e08d-7a99-4136-915c-2a7c05fab5e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 96.85 %\n"
          ]
        }
      ],
      "source": [
        "# test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
